{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python & PyTorch Coding Review — Synopsys ML Internship\n",
    "\n",
    "**Interview:** Monday, February 24, 2026, with Xin Xu (Principal R&D Engineer)\n",
    "\n",
    "Redesigned for PRACTICAL assessment of Python + PyTorch fluency.\n",
    "A senior R&D engineer will likely test:\n",
    "1. Can you write clean, correct Python? (data structures, OOP, generators)\n",
    "2. Can you manipulate tensors and data? (NumPy/PyTorch operations)\n",
    "3. Can you build a proper ML training pipeline? (Dataset, training loop, eval)\n",
    "4. Can you debug common issues? (shapes, devices, gradients, memory)\n",
    "\n",
    "**NOT likely:** \"Implement a Fourier Neural Operator from scratch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from functools import wraps\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Python Fundamentals\n",
    "\n",
    "These test clean Python — the kind of code you'd write daily at Synopsys.\n",
    "\n",
    "### Python Data Structures Cheat Sheet\n",
    "\n",
    "| Type | Mutable? | Ordered? | Example | Use Case |\n",
    "|------|----------|----------|---------|----------|\n",
    "| `list` | Yes | Yes | `[1, 2, 3]` | Dynamic collections, sequences |\n",
    "| `tuple` | No | Yes | `(1, 2, 3)` | Fixed collections, dict keys, return values |\n",
    "| `dict` | Yes | Yes (3.7+) | `{\"a\": 1}` | Key-value lookup, configs, JSON-like data |\n",
    "| `set` | Yes | No | `{1, 2, 3}` | Membership tests, deduplication |\n",
    "| `defaultdict` | Yes | Yes | `defaultdict(list)` | Grouping without KeyError |\n",
    "\n",
    "### Dictionary Operations You Must Know\n",
    "\n",
    "```python\n",
    "d = {\"lr\": 0.001, \"epochs\": 100}\n",
    "\n",
    "d[\"lr\"]                    # Access → 0.001 (KeyError if missing)\n",
    "d.get(\"batch\", 32)         # Safe access → 32 (default if missing)\n",
    "d[\"new_key\"] = \"value\"     # Insert/update\n",
    "del d[\"epochs\"]            # Delete a key\n",
    "\"lr\" in d                  # Membership check → True\n",
    "\n",
    "# Iteration patterns\n",
    "for key in d:              ...   # keys only\n",
    "for key, val in d.items(): ...   # key-value pairs\n",
    "for val in d.values():     ...   # values only\n",
    "\n",
    "# Comprehension\n",
    "squared = {k: v**2 for k, v in d.items() if isinstance(v, (int, float))}\n",
    "```\n",
    "\n",
    "### List Comprehension Patterns\n",
    "\n",
    "```python\n",
    "# Basic: [expression for item in iterable]\n",
    "squares = [x**2 for x in range(10)]\n",
    "\n",
    "# With filter: [expression for item in iterable if condition]\n",
    "even_squares = [x**2 for x in range(10) if x % 2 == 0]\n",
    "\n",
    "# Nested: [expr for outer in iterable1 for inner in iterable2]\n",
    "pairs = [(i, j) for i in range(3) for j in range(3) if i != j]\n",
    "\n",
    "# Dict comprehension\n",
    "name_to_len = {name: len(name) for name in [\"dipole\", \"patch\", \"horn\"]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Data Processing with Dictionaries & Comprehensions\n",
    "\n",
    "**Prompt:** \"We have simulation results stored as a list of dictionaries. Write a function to group them by geometry type and compute the average error per group.\"\n",
    "\n",
    "**Key concepts tested:**\n",
    "- `defaultdict(list)` — auto-creates empty list for new keys, avoiding `KeyError` or `if key not in dict` checks\n",
    "- Dict comprehension — `{k: expr for k, v in dict.items()}` to build the result in one line\n",
    "- `sum(v) / len(v)` — computing the mean without importing numpy\n",
    "\n",
    "**`defaultdict` vs regular `dict`:**\n",
    "```python\n",
    "# Without defaultdict — verbose and error-prone\n",
    "groups = {}\n",
    "for r in results:\n",
    "    key = r[\"geometry\"]\n",
    "    if key not in groups:\n",
    "        groups[key] = []       # Must check every time!\n",
    "    groups[key].append(r[\"error\"])\n",
    "\n",
    "# With defaultdict — clean and Pythonic\n",
    "groups = defaultdict(list)     # Missing keys auto-create empty list\n",
    "for r in results:\n",
    "    groups[r[\"geometry\"]].append(r[\"error\"])  # Just works\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def group_and_average(\n    results: List[Dict],\n    group_key: str = \"geometry\",\n    value_key: str = \"error\",\n) -> Dict[str, float]:\n    \"\"\"\n    Group simulation results by a key and compute the mean of a value field.\n\n    >>> results = [\n    ...     {\"geometry\": \"dipole\", \"error\": 0.05, \"freq\": 2.4e9},\n    ...     {\"geometry\": \"patch\",  \"error\": 0.12, \"freq\": 5.0e9},\n    ...     {\"geometry\": \"dipole\", \"error\": 0.03, \"freq\": 2.4e9},\n    ...     {\"geometry\": \"patch\",  \"error\": 0.08, \"freq\": 5.0e9},\n    ...     {\"geometry\": \"horn\",   \"error\": 0.02, \"freq\": 10e9},\n    ... ]\n    >>> group_and_average(results)\n    {'dipole': 0.04, 'patch': 0.1, 'horn': 0.02}\n    \"\"\"\n    # Step 1: Group values by key\n    groups = defaultdict(list)\n    for r in results:\n        key = r[group_key]        # e.g., \"dipole\"\n        value = r[value_key]      # e.g., 0.05\n        groups[key].append(value)\n\n    # Step 2: Compute average for each group\n    averages = {}\n    for key, values in groups.items():\n        averages[key] = sum(values) / len(values)\n\n    return averages"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_average(results: list[dict], group_key: str = \"geometry\", value_key: str = \"error\"):\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "    for r in results:\n",
    "        groups[r[group_key]].append(r[value_key])\n",
    "    return {k: sum(v) / len(v) for k, v in groups.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 1\n",
    "results = [\n",
    "    {\"geometry\": \"dipole\", \"error\": 0.05},\n",
    "    {\"geometry\": \"patch\",  \"error\": 0.12},\n",
    "    {\"geometry\": \"dipole\", \"error\": 0.03},\n",
    "    {\"geometry\": \"patch\",  \"error\": 0.08},\n",
    "]\n",
    "avg = group_and_average(results)\n",
    "assert abs(avg[\"dipole\"] - 0.04) < 1e-10\n",
    "assert abs(avg[\"patch\"] - 0.10) < 1e-10\n",
    "print(f\"Averages: {avg}\")\n",
    "print(\"[PASS] Exercise 1: group_and_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Generator for Large File Processing\n",
    "\n",
    "**Prompt:** \"We have a huge CSV of simulation parameters. Write a generator that yields batches of N lines without loading the entire file into memory.\"\n",
    "\n",
    "**Key concepts tested:**\n",
    "- **`yield` vs `return`:** `return` sends one result and the function is done. `yield` produces a value, *pauses* the function, and resumes where it left off on the next call. This makes the function a **generator**.\n",
    "- **Lazy evaluation:** items are produced one-at-a-time, so only one batch is in memory at any point.\n",
    "- **`with` statement:** ensures the file is properly closed even if an error occurs (context manager pattern).\n",
    "\n",
    "**Generator vs List — why it matters for large data:**\n",
    "```python\n",
    "# LIST: loads ALL 10GB into memory at once → OOM crash\n",
    "all_lines = [line for line in open(\"huge_file.csv\")]  # 10GB in RAM!\n",
    "\n",
    "# GENERATOR: processes one batch at a time → constant memory\n",
    "def batch_reader(path, batch_size=32):\n",
    "    batch = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            batch.append(line.strip())\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch       # Pause here, return batch\n",
    "                batch = []        # Resume here on next call\n",
    "    if batch:\n",
    "        yield batch               # Don't forget the last partial batch!\n",
    "\n",
    "# Usage:\n",
    "for batch in batch_reader(\"huge_file.csv\", batch_size=64):\n",
    "    process(batch)  # Only 64 lines in memory at a time\n",
    "```\n",
    "\n",
    "**Generator expression (one-liner version):**\n",
    "```python\n",
    "# List comprehension → creates full list in memory\n",
    "total = sum([x**2 for x in range(1_000_000)])  # 1M-element list\n",
    "\n",
    "# Generator expression → computes lazily, no list created\n",
    "total = sum(x**2 for x in range(1_000_000))    # Nearly zero memory\n",
    "```\n",
    "\n",
    "**This is the same principle behind `DataLoader(num_workers=N)`** — it pre-fetches batches lazily so only a few are in memory at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_reader(filepath: str, batch_size: int = 32):\n",
    "    \"\"\"\n",
    "    Yield batches of lines from a file. Memory-efficient for large files.\n",
    "\n",
    "    Why a generator?\n",
    "    - Simulation datasets can be GBs. Loading all into RAM is wasteful.\n",
    "    - Generators produce items lazily — only one batch in memory at a time.\n",
    "    - This is the same principle behind PyTorch's DataLoader with num_workers.\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            batch.append(line.strip())\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "    if batch:  # Don't forget the last incomplete batch!\n",
    "        yield batch\n",
    "\n",
    "# Note: Can't easily test without a file, but the pattern is what matters.\n",
    "# Key points: yield (not return), handles last incomplete batch, uses 'with' for cleanup.\n",
    "print(\"[INFO] Exercise 2: batch_reader — review the generator pattern above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Class Design — Simulation Result Container\n",
    "\n",
    "**Prompt:** \"Design a class to hold simulation results with proper validation.\"\n",
    "\n",
    "**OOP concepts tested:**\n",
    "\n",
    "| Concept | Syntax | Purpose |\n",
    "|---------|--------|---------|\n",
    "| `__init__` | `def __init__(self, ...)` | Constructor — validate inputs, store attributes |\n",
    "| `@property` | `@property` above a method | Makes a method look like an attribute — `obj.x` not `obj.x()`. Use for derived/computed values |\n",
    "| `@classmethod` | `@classmethod` above a method | Alternative constructor — gets `cls` (the class) as first arg. E.g., `SimResult.from_file(path)` |\n",
    "| `@staticmethod` | `@staticmethod` above a method | No access to `self` or `cls` — just a function in the class namespace |\n",
    "| `__repr__` | `def __repr__(self)` | Developer-friendly string — what shows when you `print(obj)` or type `obj` in REPL |\n",
    "| `__eq__` | `def __eq__(self, other)` | Equality check — `obj1 == obj2`. Return `NotImplemented` for wrong types |\n",
    "\n",
    "**`@property` in detail — why not just use a regular attribute?**\n",
    "```python\n",
    "class Result:\n",
    "    def __init__(self, s_params):\n",
    "        self.s_params = s_params\n",
    "\n",
    "    @property\n",
    "    def n_ports(self):\n",
    "        return self.s_params.shape[1]  # Computed from data, always in sync\n",
    "\n",
    "    @property\n",
    "    def s11_db(self):\n",
    "        return 20 * np.log10(np.abs(self.s_params[:, 0, 0]))\n",
    "\n",
    "# Usage — no parentheses! Looks like an attribute:\n",
    "r = Result(some_data)\n",
    "print(r.n_ports)    # Not r.n_ports() — cleaner API\n",
    "print(r.s11_db)     # Recomputed on access, always correct\n",
    "```\n",
    "\n",
    "**`@classmethod` — alternative constructors:**\n",
    "```python\n",
    "class Result:\n",
    "    def __init__(self, name, data):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path):           # cls = the class itself (Result)\n",
    "        data = np.load(path)\n",
    "        return cls(name=path, data=data)  # Calls __init__\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, d):\n",
    "        return cls(name=d[\"name\"], data=np.array(d[\"values\"]))\n",
    "\n",
    "# Usage:\n",
    "r1 = Result(\"test\", some_array)             # Normal constructor\n",
    "r2 = Result.from_file(\"sim_001.npz\")        # Alternative from file\n",
    "r3 = Result.from_dict({\"name\": \"x\", ...})   # Alternative from dict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationResult:\n",
    "    \"\"\"\n",
    "    Container for a single simulation result with validation.\n",
    "\n",
    "    Demonstrates:\n",
    "    - __init__ with validation\n",
    "    - __repr__ for debugging\n",
    "    - __eq__ for comparison\n",
    "    - Property for derived quantity\n",
    "    - Class method as alternative constructor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, s_params: np.ndarray, freq_ghz: np.ndarray):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            name: Design identifier (e.g., \"antenna_v3\")\n",
    "            s_params: S-parameter matrix, shape (n_freq, n_ports, n_ports), complex\n",
    "            freq_ghz: Frequency points in GHz, shape (n_freq,)\n",
    "        \"\"\"\n",
    "        if s_params.shape[0] != freq_ghz.shape[0]:\n",
    "            raise ValueError(\n",
    "                f\"Frequency dimension mismatch: s_params has {s_params.shape[0]} \"\n",
    "                f\"points but freq_ghz has {freq_ghz.shape[0]}\"\n",
    "            )\n",
    "        self.name = name\n",
    "        self.s_params = s_params\n",
    "        self.freq_ghz = freq_ghz\n",
    "\n",
    "    @property\n",
    "    def n_ports(self) -> int:\n",
    "        return self.s_params.shape[1]\n",
    "\n",
    "    @property\n",
    "    def s11_db(self) -> np.ndarray:\n",
    "        \"\"\"Return S11 in dB: 20 * log10(|S11|)\"\"\"\n",
    "        return 20.0 * np.log10(np.abs(self.s_params[:, 0, 0]) + 1e-12)\n",
    "\n",
    "    @property\n",
    "    def resonant_freq_ghz(self) -> float:\n",
    "        \"\"\"Frequency where |S11| is minimized (resonance).\"\"\"\n",
    "        return float(self.freq_ghz[np.argmin(self.s11_db)])\n",
    "\n",
    "    @classmethod\n",
    "    def from_touchstone(cls, filepath: str) -> \"SimulationResult\":\n",
    "        \"\"\"Alternative constructor: load from a .s2p touchstone file.\"\"\"\n",
    "        raise NotImplementedError(\"Touchstone parsing not implemented for demo\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"SimulationResult(name='{self.name}', \"\n",
    "            f\"ports={self.n_ports}, \"\n",
    "            f\"freq=[{self.freq_ghz[0]:.1f}-{self.freq_ghz[-1]:.1f}] GHz, \"\n",
    "            f\"resonance={self.resonant_freq_ghz:.2f} GHz)\"\n",
    "        )\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, SimulationResult):\n",
    "            return NotImplemented\n",
    "        return (\n",
    "            self.name == other.name\n",
    "            and np.allclose(self.s_params, other.s_params)\n",
    "            and np.allclose(self.freq_ghz, other.freq_ghz)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 3\n",
    "s_params = np.random.randn(10, 2, 2) + 1j * np.random.randn(10, 2, 2)\n",
    "freqs = np.linspace(1.0, 10.0, 10)\n",
    "result = SimulationResult(\"test_antenna\", s_params, freqs)\n",
    "\n",
    "assert result.n_ports == 2\n",
    "assert 1.0 <= result.resonant_freq_ghz <= 10.0\n",
    "print(f\"Result: {result}\")\n",
    "print(f\"S11 (dB): {result.s11_db}\")\n",
    "print(f\"Resonant freq: {result.resonant_freq_ghz:.2f} GHz\")\n",
    "print(\"[PASS] Exercise 3: SimulationResult\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Decorator for Timing Functions\n",
    "\n",
    "**Prompt:** \"Write a decorator to time any function. We use this to profile simulation preprocessing, training, and inference.\"\n",
    "\n",
    "**What is a decorator?**\n",
    "\n",
    "A decorator is a function that takes another function as input, wraps it with extra behavior, and returns the wrapped version. The `@decorator` syntax is just syntactic sugar:\n",
    "\n",
    "```python\n",
    "# These two are identical:\n",
    "@timer\n",
    "def train():\n",
    "    ...\n",
    "\n",
    "# is equivalent to:\n",
    "def train():\n",
    "    ...\n",
    "train = timer(train)\n",
    "```\n",
    "\n",
    "**Anatomy of a decorator:**\n",
    "```python\n",
    "def timer(func):                    # Takes a function as input\n",
    "    @wraps(func)                    # Preserves func.__name__, func.__doc__\n",
    "    def wrapper(*args, **kwargs):   # Accepts ANY arguments\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)   # Call the original function\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"{func.__name__}: {elapsed:.4f}s\")\n",
    "        return result               # Return the original result\n",
    "    return wrapper                  # Return the wrapped function\n",
    "```\n",
    "\n",
    "**Why `@wraps(func)`?**\n",
    "Without it, the wrapped function loses its identity:\n",
    "```python\n",
    "# Without @wraps:\n",
    "print(train.__name__)  # \"wrapper\" — BAD for debugging!\n",
    "\n",
    "# With @wraps:\n",
    "print(train.__name__)  # \"train\" — the real name is preserved\n",
    "```\n",
    "\n",
    "**`*args` and `**kwargs` explained:**\n",
    "```python\n",
    "def flexible(*args, **kwargs):\n",
    "    # args = tuple of positional arguments\n",
    "    # kwargs = dict of keyword arguments\n",
    "    print(f\"Positional: {args}\")    # (1, 2, 3)\n",
    "    print(f\"Keyword: {kwargs}\")     # {\"lr\": 0.01, \"epochs\": 50}\n",
    "\n",
    "flexible(1, 2, 3, lr=0.01, epochs=50)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    \"\"\"\n",
    "    Decorator that prints execution time of the wrapped function.\n",
    "\n",
    "    Why @wraps(func)?\n",
    "    - Preserves the original function's __name__, __doc__, etc.\n",
    "    - Without it, debugging shows \"wrapper\" instead of the actual function name.\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"[TIMER] {func.__name__}: {elapsed:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# Test it\n",
    "@timer\n",
    "def slow_function(n):\n",
    "    \"\"\"Example function to time.\"\"\"\n",
    "    return sum(i**2 for i in range(n))\n",
    "\n",
    "result = slow_function(1_000_000)\n",
    "print(f\"Result: {result}\")\n",
    "print(f\"Function name preserved: {slow_function.__name__}\")\n",
    "print(\"[PASS] Exercise 4: timer decorator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Error Handling & Defensive Programming\n",
    "\n",
    "**Prompt:** \"Write a function that loads and validates simulation config from a dict. Handle missing keys, wrong types, and invalid values gracefully.\"\n",
    "\n",
    "**Key concepts tested:**\n",
    "- **Fail early with clear messages** — don't let bad config silently propagate into a training run that crashes hours later\n",
    "- **`isinstance()` for type checking** — `isinstance(x, (int, float))` checks multiple types at once\n",
    "- **`.get(key, default)` for optional fields** — returns default if key is missing, never raises `KeyError`\n",
    "- **`try/except` vs validation** — validate upfront (this exercise) is better than catching errors later\n",
    "\n",
    "**Error handling patterns:**\n",
    "```python\n",
    "# Pattern 1: Validate upfront (preferred — fail early)\n",
    "def train(config):\n",
    "    if \"lr\" not in config:\n",
    "        raise ValueError(\"Missing 'lr' in config\")  # Clear message\n",
    "    if config[\"lr\"] <= 0:\n",
    "        raise ValueError(f\"lr must be positive, got {config['lr']}\")\n",
    "\n",
    "# Pattern 2: try/except for external operations (file I/O, network)\n",
    "try:\n",
    "    data = np.load(filepath)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: {filepath} not found\")\n",
    "    return None\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "    raise  # Re-raise unknown errors — don't silently swallow them!\n",
    "\n",
    "# Pattern 3: .get() with defaults for optional config\n",
    "batch_size = config.get(\"batch_size\", 32)      # 32 if missing\n",
    "device = config.get(\"device\", \"cuda\")          # \"cuda\" if missing\n",
    "```\n",
    "\n",
    "**`raise` vs `return None` vs silent default:**\n",
    "```python\n",
    "# RAISE — for required values that must be correct\n",
    "if lr <= 0:\n",
    "    raise ValueError(f\"Bad lr: {lr}\")   # Crashes immediately — good!\n",
    "\n",
    "# RETURN NONE — for optional operations that can be skipped\n",
    "def load_checkpoint(path):\n",
    "    if not os.path.exists(path):\n",
    "        return None   # Caller can check: if ckpt is not None: ...\n",
    "\n",
    "# SILENT DEFAULT — for optional config with sensible defaults\n",
    "batch = config.get(\"batch\", 32)   # Silent fallback is fine here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_config(config: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Validate and normalize a training configuration dictionary.\n",
    "\n",
    "    Returns a clean config dict with defaults filled in.\n",
    "    Raises ValueError with a clear message if something is wrong.\n",
    "    \"\"\"\n",
    "    required_keys = [\"model_type\", \"learning_rate\", \"num_epochs\"]\n",
    "    missing = [k for k in required_keys if k not in config]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required config keys: {missing}\")\n",
    "\n",
    "    # Type checking with clear messages\n",
    "    if not isinstance(config[\"learning_rate\"], (int, float)):\n",
    "        raise ValueError(\n",
    "            f\"learning_rate must be numeric, got {type(config['learning_rate']).__name__}\"\n",
    "        )\n",
    "\n",
    "    lr = float(config[\"learning_rate\"])\n",
    "    if not (1e-8 <= lr <= 1.0):\n",
    "        raise ValueError(f\"learning_rate={lr} is outside valid range [1e-8, 1.0]\")\n",
    "\n",
    "    valid_models = {\"mlp\", \"gnn\", \"fno\", \"siren\"}\n",
    "    if config[\"model_type\"] not in valid_models:\n",
    "        raise ValueError(\n",
    "            f\"model_type='{config['model_type']}' not in {valid_models}\"\n",
    "        )\n",
    "\n",
    "    # Return clean config with defaults\n",
    "    return {\n",
    "        \"model_type\": config[\"model_type\"],\n",
    "        \"learning_rate\": lr,\n",
    "        \"num_epochs\": int(config[\"num_epochs\"]),\n",
    "        \"batch_size\": config.get(\"batch_size\", 32),\n",
    "        \"hidden_dim\": config.get(\"hidden_dim\", 128),\n",
    "        \"weight_decay\": float(config.get(\"weight_decay\", 1e-4)),\n",
    "        \"device\": config.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 5 — valid config\n",
    "config = {\"model_type\": \"gnn\", \"learning_rate\": 1e-3, \"num_epochs\": 50}\n",
    "clean = validate_config(config)\n",
    "assert clean[\"batch_size\"] == 32  # Default filled in\n",
    "print(f\"Clean config: {clean}\")\n",
    "\n",
    "# Test invalid model type\n",
    "try:\n",
    "    validate_config({\"model_type\": \"transformer\", \"learning_rate\": 1e-3, \"num_epochs\": 10})\n",
    "    assert False, \"Should have raised ValueError\"\n",
    "except ValueError as e:\n",
    "    print(f\"Caught expected error: {e}\")\n",
    "\n",
    "# Test missing key\n",
    "try:\n",
    "    validate_config({\"model_type\": \"gnn\"})\n",
    "except ValueError as e:\n",
    "    print(f\"Caught expected error: {e}\")\n",
    "\n",
    "print(\"[PASS] Exercise 5: validate_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: NumPy / Tensor Operations\n",
    "\n",
    "Core data manipulation — the daily bread of ML research engineering.\n",
    "\n",
    "### Tensor Fundamentals Cheat Sheet\n",
    "\n",
    "| Concept | NumPy | PyTorch | Notes |\n",
    "|---------|-------|---------|-------|\n",
    "| Create | `np.array([1,2])` | `torch.tensor([1,2])` | PyTorch tracks gradients |\n",
    "| Zeros | `np.zeros((3,4))` | `torch.zeros(3,4)` | Note: tuple vs args |\n",
    "| Shape | `x.shape` | `x.shape` or `x.size()` | Identical |\n",
    "| Reshape | `x.reshape(2,3)` | `x.reshape(2,3)` or `x.view(2,3)` | `.view()` requires contiguous memory |\n",
    "| Transpose | `x.T` | `x.T` or `x.permute(1,0)` | `.permute()` for >2D |\n",
    "| Matrix multiply | `A @ B` | `A @ B` or `torch.matmul(A,B)` | Same operator |\n",
    "| Element-wise | `A * B` | `A * B` | Broadcasting applies |\n",
    "| Sum/Mean | `x.sum(axis=0)` | `x.sum(dim=0)` | `axis` vs `dim` keyword |\n",
    "| Concatenate | `np.concatenate` | `torch.cat` | Along existing dim |\n",
    "| Stack | `np.stack` | `torch.stack` | Creates new dim |\n",
    "\n",
    "### Shape Manipulation — The Most Common Source of Bugs\n",
    "\n",
    "```python\n",
    "x = torch.randn(8, 3, 64, 64)   # (batch, channels, H, W)\n",
    "\n",
    "# Flatten spatial dims\n",
    "x.reshape(8, 3, -1)              # (8, 3, 4096)  — -1 = infer\n",
    "\n",
    "# Add a dimension (for broadcasting)\n",
    "x.unsqueeze(0)                   # (1, 8, 3, 64, 64)\n",
    "x.unsqueeze(-1)                  # (8, 3, 64, 64, 1)\n",
    "\n",
    "# Remove size-1 dimensions\n",
    "x.unsqueeze(0).squeeze(0)        # Back to (8, 3, 64, 64)\n",
    "\n",
    "# keepdim=True — critical for broadcasting after reduction\n",
    "mean = x.mean(dim=(-2,-1))              # (8, 3) — dims gone\n",
    "mean = x.mean(dim=(-2,-1), keepdim=True) # (8, 3, 1, 1) — dims kept\n",
    "# Now x - mean works via broadcasting!\n",
    "```\n",
    "\n",
    "### Broadcasting Rules (must memorize)\n",
    "\n",
    "Two tensors are broadcastable if, reading dimensions **right to left**:\n",
    "1. Dimensions are equal, OR\n",
    "2. One of them is 1, OR\n",
    "3. One of them doesn't exist (treated as 1)\n",
    "\n",
    "```python\n",
    "# Example: (8, 3, 64, 64) - (3, 1, 1) → works!\n",
    "# Reading right to left:  64 vs 1 ✓,  64 vs 1 ✓,  3 vs 3 ✓,  8 vs (none) ✓\n",
    "\n",
    "# Example: (8, 3) - (8, 1) → (8, 3) ✓\n",
    "# Example: (8, 3) - (4, 3) → ERROR! 8 ≠ 4 and neither is 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Broadcasting & Vectorized Operations\n",
    "\n",
    "**Prompt:** \"Compute pairwise Euclidean distances between two sets of points WITHOUT loops.\"\n",
    "\n",
    "**Key concepts tested:**\n",
    "- **Vectorization** — replacing Python loops with tensor operations for 100-1000x speedup\n",
    "- **Broadcasting** — automatic expansion of shapes so operations work on different-sized tensors\n",
    "- **The expansion trick:** `||a - b||² = ||a||² + ||b||² - 2·a·b` avoids creating the full `(N, M, D)` difference tensor\n",
    "\n",
    "**Why not just use a loop?**\n",
    "```python\n",
    "# SLOW: O(N×M) Python iterations, each calling into C++\n",
    "for i in range(N):\n",
    "    for j in range(M):\n",
    "        dist[i,j] = ((x[i] - y[j])**2).sum().sqrt()\n",
    "\n",
    "# FAST: One BLAS call for the matrix multiply, vectorized norms\n",
    "xx = (x*x).sum(dim=1, keepdim=True)  # (N,1) — squared norms\n",
    "yy = (y*y).sum(dim=1, keepdim=True).T # (1,M) — transposed\n",
    "xy = x @ y.T                          # (N,M) — dot products\n",
    "dist = (xx + yy - 2*xy).clamp(min=0).sqrt()\n",
    "```\n",
    "\n",
    "**Broadcasting in this exercise:**\n",
    "```\n",
    "xx shape: (N, 1)  ─┐\n",
    "yy shape: (1, M)  ─┤→ xx + yy broadcasts to (N, M)\n",
    "xy shape: (N, M)  ─┘\n",
    "```\n",
    "\n",
    "**Built-in alternative:** `torch.cdist(x, y)` — use this in production, know the manual version for interviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute pairwise Euclidean distances between two point sets.\n",
    "\n",
    "    Args:\n",
    "        x: shape (N, D) — N points in D dimensions\n",
    "        y: shape (M, D) — M points in D dimensions\n",
    "\n",
    "    Returns:\n",
    "        dist: shape (N, M) — dist[i,j] = ||x[i] - y[j]||\n",
    "\n",
    "    Key concept: ||a - b||^2 = ||a||^2 + ||b||^2 - 2*a·b\n",
    "    This avoids the O(NMD) loop and uses O(NM + ND + MD) with BLAS.\n",
    "    \"\"\"\n",
    "    # Method 1: Using the expansion trick (numerically less stable but fast)\n",
    "    xx = (x * x).sum(dim=1, keepdim=True)   # (N, 1)\n",
    "    yy = (y * y).sum(dim=1, keepdim=True).T  # (1, M)\n",
    "    xy = x @ y.T                              # (N, M)\n",
    "    dist_sq = xx + yy - 2 * xy\n",
    "    # Clamp to avoid negative values from numerical errors\n",
    "    return torch.sqrt(dist_sq.clamp(min=0.0))\n",
    "\n",
    "    # Method 2 (simpler, more memory): torch.cdist(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 6\n",
    "x = torch.randn(5, 3)\n",
    "y = torch.randn(7, 3)\n",
    "dist = pairwise_distances(x, y)\n",
    "\n",
    "assert dist.shape == (5, 7)\n",
    "assert (dist >= 0).all()\n",
    "\n",
    "# Verify against torch.cdist\n",
    "expected = torch.cdist(x, y)\n",
    "assert torch.allclose(dist, expected, atol=1e-5), f\"Max diff: {(dist - expected).abs().max()}\"\n",
    "\n",
    "print(f\"Distance matrix shape: {dist.shape}\")\n",
    "print(f\"Sample distances: {dist[0, :3]}\")\n",
    "print(\"[PASS] Exercise 6: pairwise_distances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Advanced Indexing — Gather and Scatter\n",
    "\n",
    "**Prompt:** \"Given node features and an edge list, gather source/target node features for all edges, then scatter messages back to nodes.\"\n",
    "\n",
    "This is the **fundamental operation behind ALL graph neural networks** — including MeshGraphNets (directly relevant to HFSS mesh simulation).\n",
    "\n",
    "**Key concepts tested:**\n",
    "- **Fancy indexing:** `tensor[index_tensor]` selects rows by index — this is how we \"gather\" features\n",
    "- **`index_add_`:** The reverse operation — \"scatter\" values back, accumulating at specified indices\n",
    "- **Edge list format:** `edge_index` shape `(2, E)` where row 0 = source nodes, row 1 = target nodes\n",
    "\n",
    "**Step-by-step walkthrough:**\n",
    "```python\n",
    "node_features = torch.tensor([       # 4 nodes, 3 features each\n",
    "    [1.0, 0.0, 0.0],  # node 0\n",
    "    [0.0, 1.0, 0.0],  # node 1\n",
    "    [0.0, 0.0, 1.0],  # node 2\n",
    "    [1.0, 1.0, 1.0],  # node 3\n",
    "])\n",
    "\n",
    "edge_index = torch.tensor([\n",
    "    [0, 1, 2],   # source: 0→1, 1→2, 2→3\n",
    "    [1, 2, 3],   # target\n",
    "])\n",
    "\n",
    "# GATHER: get features for each edge's endpoints\n",
    "src_feat = node_features[edge_index[0]]  # [[1,0,0], [0,1,0], [0,0,1]]\n",
    "tgt_feat = node_features[edge_index[1]]  # [[0,1,0], [0,0,1], [1,1,1]]\n",
    "\n",
    "# COMPUTE MESSAGES (e.g., difference)\n",
    "messages = src_feat - tgt_feat  # [[1,-1,0], [0,1,-1], [-1,-1,0]]\n",
    "\n",
    "# SCATTER: aggregate messages at target nodes\n",
    "aggregated = torch.zeros_like(node_features)\n",
    "aggregated.index_add_(0, edge_index[1], messages)\n",
    "# Node 1 gets message from edge 0: [1,-1,0]\n",
    "# Node 2 gets message from edge 1: [0,1,-1]\n",
    "# Node 3 gets message from edge 2: [-1,-1,0]\n",
    "```\n",
    "\n",
    "**Scatter operations comparison:**\n",
    "| Method | Operation | Notes |\n",
    "|--------|-----------|-------|\n",
    "| `index_add_(dim, idx, src)` | `out[idx[i]] += src[i]` | Sum aggregation (most common) |\n",
    "| `index_copy_(dim, idx, src)` | `out[idx[i]] = src[i]` | Overwrites (last write wins) |\n",
    "| `scatter_add(dim, idx, src)` | Similar to index_add_ | Different index shape convention |\n",
    "| `scatter_reduce(dim, idx, src, \"mean\")` | Mean aggregation | PyTorch 2.0+ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_scatter_demo(\n",
    "    node_features: torch.Tensor,  # (num_nodes, feature_dim)\n",
    "    edge_index: torch.Tensor,      # (2, num_edges) — [src; tgt]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    GNN-style gather-scatter: collect neighbor info, aggregate per node.\n",
    "\n",
    "    This is the fundamental operation behind ALL graph neural networks.\n",
    "    Understanding indexing here is critical for mesh-based simulation ML.\n",
    "    \"\"\"\n",
    "    src, tgt = edge_index[0], edge_index[1]\n",
    "\n",
    "    # GATHER: get features for each edge's source and target\n",
    "    src_feat = node_features[src]  # (num_edges, feature_dim)\n",
    "    tgt_feat = node_features[tgt]  # (num_edges, feature_dim)\n",
    "\n",
    "    # Compute messages (simple example: difference of features)\n",
    "    messages = src_feat - tgt_feat  # (num_edges, feature_dim)\n",
    "\n",
    "    # SCATTER: aggregate messages back to target nodes (sum)\n",
    "    aggregated = torch.zeros_like(node_features)\n",
    "    aggregated.index_add_(0, tgt, messages)\n",
    "\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 7\n",
    "node_feat = torch.randn(4, 8)\n",
    "edges = torch.tensor([[0, 1, 2, 3],   # source nodes\n",
    "                       [1, 2, 3, 0]])  # target nodes (a ring graph)\n",
    "\n",
    "agg = gather_scatter_demo(node_feat, edges)\n",
    "assert agg.shape == (4, 8)\n",
    "\n",
    "# Verify: node 1 receives message from node 0 → msg = feat[0] - feat[1]\n",
    "expected_msg_to_1 = node_feat[0] - node_feat[1]\n",
    "assert torch.allclose(agg[1], expected_msg_to_1)\n",
    "\n",
    "print(f\"Aggregated shape: {agg.shape}\")\n",
    "print(\"[PASS] Exercise 7: gather_scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Masking & Boolean Indexing\n",
    "\n",
    "**Prompt:** \"Filter simulation data: keep only samples where the error is below a threshold and the frequency is within a range.\"\n",
    "\n",
    "**Key concepts tested:**\n",
    "- **Boolean masks** — comparison operators return boolean tensors: `x > 5` → `tensor([False, True, True, ...])`\n",
    "- **Boolean indexing** — `tensor[bool_mask]` keeps only elements where mask is `True`\n",
    "- **Combining masks** — use `&` (and), `|` (or), `~` (not). **NOT** Python `and`/`or` (those don't work on tensors!)\n",
    "\n",
    "**Boolean mask operations:**\n",
    "```python\n",
    "errors = torch.tensor([0.05, 0.15, 0.03, 0.20, 0.08])\n",
    "\n",
    "# Create masks (each returns a boolean tensor)\n",
    "low_error = errors < 0.1           # [True, False, True, False, True]\n",
    "high_error = errors > 0.15         # [False, False, False, True, False]\n",
    "\n",
    "# Combine with bitwise operators (NOT Python and/or!)\n",
    "combined = low_error & ~high_error  # AND + NOT\n",
    "either = low_error | high_error     # OR\n",
    "\n",
    "# Apply mask to select elements\n",
    "filtered = errors[low_error]        # tensor([0.05, 0.03, 0.08])\n",
    "\n",
    "# Count matching elements\n",
    "n_good = low_error.sum().item()     # 3\n",
    "\n",
    "# Apply same mask to multiple tensors (keep them aligned!)\n",
    "filtered_errors = errors[low_error]\n",
    "filtered_freqs = frequencies[low_error]  # Same mask → same indices\n",
    "filtered_fields = fields[low_error]\n",
    "```\n",
    "\n",
    "**Common mistake — using Python `and` instead of `&`:**\n",
    "```python\n",
    "# WRONG: Python 'and' tries to convert entire tensor to bool\n",
    "mask = (errors < 0.1) and (freqs > 1e9)  # RuntimeError!\n",
    "\n",
    "# RIGHT: Bitwise '&' operates element-wise\n",
    "mask = (errors < 0.1) & (freqs > 1e9)    # Works correctly\n",
    "\n",
    "# NOTE: Parentheses are required because & has higher precedence than <\n",
    "```\n",
    "\n",
    "**Why masking matters for simulation data:**\n",
    "- Filter out diverged simulations (error > threshold)\n",
    "- Select frequency bands of interest\n",
    "- Remove padding in variable-size batches (see Exercise 11's `mask` field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_simulation_data(\n",
    "    errors: torch.Tensor,       # (N,)\n",
    "    frequencies: torch.Tensor,  # (N,)\n",
    "    fields: torch.Tensor,       # (N, H, W) — field data\n",
    "    max_error: float = 0.1,\n",
    "    freq_range: Tuple[float, float] = (1e9, 10e9),\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Filter data using boolean masks. Returns filtered errors, freqs, fields.\n",
    "\n",
    "    Key concepts:\n",
    "    - Boolean indexing: tensor[mask] returns elements where mask is True\n",
    "    - Combining masks with & (and), | (or), ~ (not)\n",
    "    - This is vectorized — no Python loops needed\n",
    "    \"\"\"\n",
    "    # Build boolean masks\n",
    "    error_mask = errors < max_error\n",
    "    freq_mask = (frequencies >= freq_range[0]) & (frequencies <= freq_range[1])\n",
    "\n",
    "    # Combine masks\n",
    "    valid_mask = error_mask & freq_mask\n",
    "\n",
    "    # Apply mask to all tensors consistently\n",
    "    return errors[valid_mask], frequencies[valid_mask], fields[valid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 8\n",
    "errors = torch.tensor([0.05, 0.15, 0.03, 0.20, 0.08])\n",
    "freqs = torch.tensor([2e9, 5e9, 3e9, 15e9, 8e9])\n",
    "fields = torch.randn(5, 4, 4)\n",
    "\n",
    "e_filt, f_filt, fd_filt = filter_simulation_data(errors, freqs, fields)\n",
    "\n",
    "print(f\"Original: {len(errors)} samples\")\n",
    "print(f\"After filtering: {len(e_filt)} samples\")\n",
    "print(f\"Kept errors: {e_filt}\")\n",
    "print(f\"Kept freqs: {f_filt}\")\n",
    "\n",
    "# error < 0.1: indices 0,2,4 (0.05, 0.03, 0.08)\n",
    "# freq in [1e9, 10e9]: indices 0,1,2,4 (2e9, 5e9, 3e9, 8e9)\n",
    "# Both: indices 0,2,4 → 3 samples\n",
    "assert len(e_filt) == 3\n",
    "print(\"[PASS] Exercise 8: filter_simulation_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Reshaping & Per-Sample Metrics\n",
    "\n",
    "**Prompt:** \"Given a batch of 2D field predictions, compute the relative L2 error per sample (not averaged across the batch).\"\n",
    "\n",
    "**Key concepts tested:**\n",
    "- **`.reshape(batch, -1)`** — flatten spatial dims while keeping batch dim intact\n",
    "- **Reducing over the right dimension** — `dim=1` reduces spatial, keeps batch\n",
    "- **`keepdim=True`** — keeps the reduced dimension as size 1 for broadcasting\n",
    "\n",
    "**Reshape vs View vs Flatten:**\n",
    "```python\n",
    "x = torch.randn(4, 16, 16)   # (batch, H, W)\n",
    "\n",
    "# Method 1: reshape — always works, may copy data\n",
    "x.reshape(4, -1)              # (4, 256)  — -1 infers 16*16=256\n",
    "\n",
    "# Method 2: view — only works if tensor is contiguous in memory\n",
    "x.view(4, -1)                 # (4, 256)  — fails after .permute()\n",
    "\n",
    "# Method 3: flatten — explicit and readable\n",
    "x.flatten(start_dim=1)        # (4, 256)  — flatten from dim 1 onward\n",
    "\n",
    "# RULE: Use .reshape() unless you specifically need .view()'s error\n",
    "# on non-contiguous tensors (rare). .flatten() is most readable.\n",
    "```\n",
    "\n",
    "**Relative L2 error — the standard metric for physics surrogates:**\n",
    "```\n",
    "relative_L2 = ||pred - target||₂ / ||target||₂\n",
    "\n",
    "# Per-sample (this exercise): shape (batch,)\n",
    "# Global (less useful):       single scalar\n",
    "```\n",
    "\n",
    "**Why per-sample, not batch-averaged?**\n",
    "- You need to know WHICH samples have high error\n",
    "- Batch-average hides outliers — one bad prediction gets buried\n",
    "- In production: flag samples with error > threshold for full simulation\n",
    "\n",
    "**Dimension reduction pattern:**\n",
    "```python\n",
    "x = torch.randn(4, 256)      # (batch, features)\n",
    "\n",
    "# Reduce features, keep batch:\n",
    "norm = torch.norm(x, dim=1)   # (4,)  — one value per sample\n",
    "\n",
    "# Reduce batch, keep features:\n",
    "mean = x.mean(dim=0)          # (256,) — one value per feature\n",
    "\n",
    "# Reduce both:\n",
    "total = x.sum()               # scalar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_sample_relative_l2(\n",
    "    pred: torch.Tensor,   # (batch, H, W)\n",
    "    target: torch.Tensor,  # (batch, H, W)\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute relative L2 error for each sample: ||pred - target|| / ||target||\n",
    "\n",
    "    Returns shape (batch,) — one error value per sample.\n",
    "\n",
    "    Key concept: Use .reshape(batch, -1) to flatten spatial dims,\n",
    "    then reduce over the flattened dim only (not the batch dim).\n",
    "    \"\"\"\n",
    "    batch = pred.shape[0]\n",
    "    # Flatten spatial dimensions\n",
    "    p = pred.reshape(batch, -1)   # (batch, H*W)\n",
    "    t = target.reshape(batch, -1)  # (batch, H*W)\n",
    "\n",
    "    # L2 norm along the spatial dimension (dim=1), keep batch dim\n",
    "    diff_norm = torch.norm(p - t, dim=1)    # (batch,)\n",
    "    target_norm = torch.norm(t, dim=1)       # (batch,)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    return diff_norm / target_norm.clamp(min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 9\n",
    "pred = torch.randn(4, 16, 16)\n",
    "target = torch.randn(4, 16, 16) + 5  # Offset so target_norm > 0\n",
    "rel_err = per_sample_relative_l2(pred, target)\n",
    "\n",
    "assert rel_err.shape == (4,)\n",
    "assert (rel_err >= 0).all()\n",
    "\n",
    "# Perfect prediction should give 0 error\n",
    "perfect_err = per_sample_relative_l2(target, target)\n",
    "assert torch.allclose(perfect_err, torch.zeros(4), atol=1e-6)\n",
    "\n",
    "print(f\"Per-sample relative L2: {rel_err}\")\n",
    "print(f\"Perfect prediction error: {perfect_err}\")\n",
    "print(\"[PASS] Exercise 9: per_sample_relative_l2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: Per-Sample Normalization\n",
    "\n",
    "**Prompt:** \"Normalize each sample in a batch independently (zero mean, unit variance) along the spatial dimensions.\"\n",
    "\n",
    "**Key concepts tested:**\n",
    "- **`keepdim=True`** — essential for broadcasting the mean/std back to original shape\n",
    "- **`.clamp(min=1e-8)`** — avoid division by zero for constant-valued regions\n",
    "- **Understanding normalization types** — which dims to reduce over\n",
    "\n",
    "**Normalization types compared (critical interview topic):**\n",
    "\n",
    "| Type | Reduces over | Shape kept | Use case |\n",
    "|------|-------------|------------|----------|\n",
    "| **BatchNorm** | Batch + Spatial `(N,H,W)` | `(C,)` | Standard for images, needs large batches |\n",
    "| **LayerNorm** | Channel + Spatial `(C,H,W)` | `(N,)` | Transformers, small-batch friendly |\n",
    "| **InstanceNorm** | Spatial `(H,W)` | `(N,C)` | Style transfer, per-sample normalization |\n",
    "| **GroupNorm** | Group of channels + Spatial | `(N, G)` | Compromise between BN and LN |\n",
    "\n",
    "```python\n",
    "x = torch.randn(2, 3, 8, 8)  # (batch=2, channels=3, H=8, W=8)\n",
    "\n",
    "# BatchNorm: stats across batch+spatial, one mean/var per channel\n",
    "nn.BatchNorm2d(3)      # learns γ,β per channel; needs batch > 1\n",
    "\n",
    "# LayerNorm: stats per sample across channels+spatial\n",
    "nn.LayerNorm([3,8,8])  # normalizes each sample independently\n",
    "\n",
    "# InstanceNorm: stats per sample per channel across spatial\n",
    "nn.InstanceNorm2d(3)   # each (sample, channel) normalized separately\n",
    "\n",
    "# This exercise: manual InstanceNorm (no learnable params)\n",
    "mean = x.mean(dim=(-2,-1), keepdim=True)   # (2, 3, 1, 1)\n",
    "std  = x.std(dim=(-2,-1), keepdim=True)    # (2, 3, 1, 1)\n",
    "normed = (x - mean) / std.clamp(min=1e-8)  # Broadcasting: (2,3,8,8)\n",
    "```\n",
    "\n",
    "**Why `keepdim=True` matters:**\n",
    "```python\n",
    "x = torch.randn(2, 3, 8, 8)\n",
    "\n",
    "# WITHOUT keepdim: mean has shape (2, 3) → can't subtract from (2, 3, 8, 8)\n",
    "mean = x.mean(dim=(-2,-1))                  # (2, 3) — WRONG shape!\n",
    "# x - mean → RuntimeError or silent broadcasting bug!\n",
    "\n",
    "# WITH keepdim: mean has shape (2, 3, 1, 1) → broadcasts correctly\n",
    "mean = x.mean(dim=(-2,-1), keepdim=True)     # (2, 3, 1, 1) — RIGHT!\n",
    "# x - mean → (2, 3, 8, 8) — works via broadcasting\n",
    "```\n",
    "\n",
    "**For simulation data at Synopsys:** each simulation has different field magnitudes (e.g., E-field for a 2 GHz antenna vs 10 GHz). Per-sample normalization ensures the model sees consistent scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_sample_normalize(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalize each sample to zero mean and unit variance.\n",
    "\n",
    "    Input:  (batch, channels, H, W)\n",
    "    Output: (batch, channels, H, W) — each sample independently normalized\n",
    "\n",
    "    This is InstanceNorm without learnable params.\n",
    "    Useful for simulation data where each sample has different magnitude.\n",
    "    \"\"\"\n",
    "    # Compute mean and std over spatial dims (H, W), keep batch and channel\n",
    "    mean = x.mean(dim=(-2, -1), keepdim=True)  # (B, C, 1, 1)\n",
    "    std = x.std(dim=(-2, -1), keepdim=True)    # (B, C, 1, 1)\n",
    "    return (x - mean) / std.clamp(min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 10\n",
    "x = torch.randn(2, 3, 8, 8) * 100 + 50  # Arbitrary scale\n",
    "normed = per_sample_normalize(x)\n",
    "\n",
    "# Check zero mean per sample/channel\n",
    "means = normed.mean(dim=(-2, -1))\n",
    "stds = normed.std(dim=(-2, -1))\n",
    "assert torch.allclose(means, torch.zeros_like(means), atol=1e-5)\n",
    "\n",
    "print(f\"Input mean range: [{x.mean(dim=(-2,-1)).min():.1f}, {x.mean(dim=(-2,-1)).max():.1f}]\")\n",
    "print(f\"Normalized mean range: [{means.min():.6f}, {means.max():.6f}]\")\n",
    "print(f\"Normalized std range: [{stds.min():.4f}, {stds.max():.4f}]\")\n",
    "print(\"[PASS] Exercise 10: per_sample_normalize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: PyTorch Practical Patterns\n",
    "\n",
    "Building real ML pipelines — what you'd actually do on the job.\n",
    "\n",
    "### PyTorch Pipeline Overview\n",
    "\n",
    "```\n",
    "Raw Data (.npz, .csv, .h5)\n",
    "    ↓\n",
    "Dataset  ──→ __getitem__(idx) returns one sample\n",
    "    ↓\n",
    "DataLoader ──→ batches, shuffles, multi-process loading\n",
    "    ↓\n",
    "Model (nn.Module) ──→ forward(x) returns predictions\n",
    "    ↓\n",
    "Loss Function ──→ scalar loss value\n",
    "    ↓\n",
    "loss.backward() ──→ computes gradients\n",
    "    ↓\n",
    "optimizer.step() ──→ updates weights\n",
    "    ↓\n",
    "scheduler.step() ──→ adjusts learning rate\n",
    "    ↓\n",
    "Evaluation (model.eval() + torch.no_grad())\n",
    "    ↓\n",
    "Save/Load (torch.save / torch.load state_dict)\n",
    "```\n",
    "\n",
    "### Key PyTorch Classes to Know\n",
    "\n",
    "| Class | Purpose | You implement |\n",
    "|-------|---------|---------------|\n",
    "| `Dataset` | Wraps your data | `__len__`, `__getitem__` |\n",
    "| `DataLoader` | Batching + shuffling | (use as-is, maybe custom `collate_fn`) |\n",
    "| `nn.Module` | Neural network base | `__init__`, `forward` |\n",
    "| `optim.Adam` | Optimizer | (use as-is) |\n",
    "| `lr_scheduler` | LR schedule | (use as-is) |\n",
    "| `nn.MSELoss` | Loss function | (or write custom) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11: Custom Dataset for Variable-Size Simulation Data\n",
    "\n",
    "**Prompt:** \"Write a PyTorch Dataset for loading simulation field data. Each sample has different spatial resolution (variable-size meshes).\"\n",
    "\n",
    "**Key concepts tested:**\n",
    "- **`Dataset` interface** — only two methods: `__len__()` and `__getitem__(idx)`\n",
    "- **Lazy loading** — don't load all data in `__init__`, load per-sample in `__getitem__`\n",
    "- **Custom `collate_fn`** — how to batch variable-size data\n",
    "\n",
    "**`Dataset` vs `IterableDataset`:**\n",
    "```python\n",
    "# Map-style Dataset (this exercise) — most common\n",
    "class MyDataset(Dataset):\n",
    "    def __len__(self):        return N         # Total number of samples\n",
    "    def __getitem__(self, i): return data[i]   # Access by index\n",
    "# Supports: shuffling, random access, len(), sampler\n",
    "\n",
    "# IterableDataset — for streaming data (huge files, network)\n",
    "class MyStream(IterableDataset):\n",
    "    def __iter__(self):\n",
    "        for line in open(\"huge.csv\"):\n",
    "            yield process(line)\n",
    "# No shuffling, no len(), no random access\n",
    "```\n",
    "\n",
    "**Why lazy loading?**\n",
    "```python\n",
    "# BAD: loads entire dataset into RAM at init — may OOM\n",
    "class BadDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data = [np.load(f) for f in glob(data_dir)]  # 100GB in RAM!\n",
    "\n",
    "# GOOD: only stores file paths at init, loads one sample at a time\n",
    "class GoodDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.paths = sorted(glob(data_dir))  # Just paths — kilobytes\n",
    "    def __getitem__(self, i):\n",
    "        return np.load(self.paths[i])         # Load on demand\n",
    "```\n",
    "\n",
    "**Custom `collate_fn` — when default stacking doesn't work:**\n",
    "```python\n",
    "# Default collate: torch.stack(samples) → requires same shape!\n",
    "# Variable-size data (meshes, sequences) needs custom handling:\n",
    "\n",
    "# Option 1: Pad to max size + mask (this exercise)\n",
    "# Option 2: Concatenate + batch index (PyG style)\n",
    "# Option 3: Nested tensors (PyTorch 2.0+)\n",
    "\n",
    "# DataLoader usage:\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,               # Shuffle for training\n",
    "    num_workers=4,               # Parallel data loading\n",
    "    collate_fn=my_collate,       # Custom batching\n",
    "    pin_memory=True,             # Faster CPU→GPU transfer\n",
    ")\n",
    "```\n",
    "\n",
    "**Key design decisions in this exercise:**\n",
    "1. **Lazy loading** — `__init__` only stores file paths\n",
    "2. **Return dict** (not tuple) — `{\"params\": ..., \"field\": ..., \"coords\": ...}` is self-documenting\n",
    "3. **Padding + mask** — mask is CRITICAL: loss must ignore padded values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for simulation field data stored as .npz files.\n",
    "\n",
    "    Each file contains:\n",
    "      - 'params': input parameters (e.g., geometry, frequency), shape (P,)\n",
    "      - 'field':  output field values, shape (N_i, F) — N_i varies per sample\n",
    "      - 'coords': node coordinates, shape (N_i, D)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir: str, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        # Only store file paths at init — lazy loading\n",
    "        self.file_paths = sorted(\n",
    "            [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".npz\")]\n",
    "        )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        data = np.load(self.file_paths[idx])\n",
    "\n",
    "        sample = {\n",
    "            \"params\": torch.tensor(data[\"params\"], dtype=torch.float32),\n",
    "            \"coords\": torch.tensor(data[\"coords\"], dtype=torch.float32),\n",
    "            \"field\": torch.tensor(data[\"field\"], dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "def collate_variable_size(batch: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Custom collate function for variable-size simulation data.\n",
    "\n",
    "    Since each sample has different number of nodes N_i, we can't just stack.\n",
    "    Options:\n",
    "      1. Pad to max size (shown here) — simple, works with standard PyTorch\n",
    "      2. Concatenate with batch index (PyG-style) — more memory efficient\n",
    "      3. Use nested tensors (PyTorch 2.0+)\n",
    "    \"\"\"\n",
    "    # Fixed-size: stack normally\n",
    "    params = torch.stack([s[\"params\"] for s in batch])  # (B, P)\n",
    "\n",
    "    # Variable-size: pad to max\n",
    "    max_nodes = max(s[\"coords\"].shape[0] for s in batch)\n",
    "    coord_dim = batch[0][\"coords\"].shape[1]\n",
    "    field_dim = batch[0][\"field\"].shape[1]\n",
    "\n",
    "    padded_coords = torch.zeros(len(batch), max_nodes, coord_dim)\n",
    "    padded_fields = torch.zeros(len(batch), max_nodes, field_dim)\n",
    "    masks = torch.zeros(len(batch), max_nodes, dtype=torch.bool)\n",
    "\n",
    "    for i, s in enumerate(batch):\n",
    "        n = s[\"coords\"].shape[0]\n",
    "        padded_coords[i, :n] = s[\"coords\"]\n",
    "        padded_fields[i, :n] = s[\"field\"]\n",
    "        masks[i, :n] = True  # True = valid node, False = padding\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"coords\": padded_coords,\n",
    "        \"field\": padded_fields,\n",
    "        \"mask\": masks,  # CRITICAL: loss/metrics must use this mask!\n",
    "    }\n",
    "\n",
    "# Usage:\n",
    "# loader = DataLoader(dataset, batch_size=8, collate_fn=collate_variable_size)\n",
    "print(\"[INFO] Exercise 11: SimulationDataset + collate_variable_size defined\")\n",
    "print(\"       (Requires .npz files on disk to test — review the pattern)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12: Complete Training Loop with Best Practices\n",
    "\n",
    "**Prompt:** \"Write a training function with validation, early stopping, checkpointing, and proper device management.\"\n",
    "\n",
    "**Training loop components explained:**\n",
    "\n",
    "| Component | What it does | Why it matters |\n",
    "|-----------|-------------|----------------|\n",
    "| `optimizer.zero_grad()` | Clears old gradients | Gradients accumulate by default! |\n",
    "| `loss.backward()` | Computes gradients via backprop | Populates `.grad` for all parameters |\n",
    "| `clip_grad_norm_` | Caps gradient magnitude | Prevents exploding gradients |\n",
    "| `optimizer.step()` | Updates weights using gradients | The actual learning step |\n",
    "| `scheduler.step()` | Adjusts learning rate | Cosine annealing, step decay, etc. |\n",
    "| `model.train()` | Enables dropout + BN training mode | Must call before training |\n",
    "| `model.eval()` | Disables dropout, uses running BN stats | Must call before validation |\n",
    "| `torch.no_grad()` | Disables gradient tracking | Saves memory during validation |\n",
    "\n",
    "**Mixed Precision Training (AMP) — why and how:**\n",
    "```python\n",
    "# WHY: float16 is 2x faster on GPU, uses half the memory\n",
    "# HOW: autocast converts eligible ops to float16 automatically\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "with torch.amp.autocast(\"cuda\"):         # Forward pass in float16\n",
    "    pred = model(x)\n",
    "    loss = criterion(pred, y)\n",
    "\n",
    "scaler.scale(loss).backward()             # Scale loss to prevent underflow\n",
    "scaler.unscale_(optimizer)                # Unscale before clipping\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "scaler.step(optimizer)                    # Step with unscaled gradients\n",
    "scaler.update()                           # Adjust scale factor\n",
    "```\n",
    "\n",
    "**Early stopping — prevent overfitting:**\n",
    "```python\n",
    "best_val_loss = float(\"inf\")\n",
    "patience_counter = 0\n",
    "\n",
    "if val_loss < best_val_loss:\n",
    "    best_val_loss = val_loss\n",
    "    patience_counter = 0\n",
    "    torch.save(model.state_dict(), \"best.pt\")  # Save best\n",
    "else:\n",
    "    patience_counter += 1\n",
    "    if patience_counter >= patience:            # No improvement for N epochs\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "```\n",
    "\n",
    "**Checkpointing — save everything needed to resume:**\n",
    "```python\n",
    "# SAVE (not just model — also optimizer, epoch, loss for resuming)\n",
    "torch.save({\n",
    "    \"epoch\": epoch,\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"val_loss\": val_loss,\n",
    "}, \"checkpoint.pt\")\n",
    "\n",
    "# LOAD\n",
    "ckpt = torch.load(\"checkpoint.pt\", weights_only=True)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "start_epoch = ckpt[\"epoch\"] + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int = 100,\n",
    "    lr: float = 1e-3,\n",
    "    patience: int = 10,\n",
    "    save_path: str = \"best_model.pt\",\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Production-quality training loop.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    scaler = torch.amp.GradScaler(\"cuda\")  # For mixed precision\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ---- TRAINING ----\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            x = batch[\"input\"].to(device)\n",
    "            y = batch[\"target\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)  # Slightly faster\n",
    "\n",
    "            # Mixed precision forward pass\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                pred = model(x)\n",
    "                loss = F.mse_loss(pred, y)\n",
    "\n",
    "            # Mixed precision backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()  # .item() to avoid memory leak!\n",
    "            num_batches += 1\n",
    "\n",
    "        train_loss /= num_batches\n",
    "        scheduler.step()\n",
    "\n",
    "        # ---- VALIDATION ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        num_val_batches = 0\n",
    "\n",
    "        with torch.no_grad():  # CRITICAL: save memory\n",
    "            for batch in val_loader:\n",
    "                x = batch[\"input\"].to(device)\n",
    "                y = batch[\"target\"].to(device)\n",
    "\n",
    "                with torch.amp.autocast(\"cuda\"):\n",
    "                    pred = model(x)\n",
    "                    loss = F.mse_loss(pred, y)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                num_val_batches += 1\n",
    "\n",
    "        val_loss /= num_val_batches\n",
    "\n",
    "        # ---- EARLY STOPPING & CHECKPOINTING ----\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"val_loss\": val_loss,\n",
    "            }, save_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            print(\n",
    "                f\"Epoch {epoch:3d} | \"\n",
    "                f\"Train: {train_loss:.6f} | \"\n",
    "                f\"Val: {val_loss:.6f} | \"\n",
    "                f\"LR: {current_lr:.2e} | \"\n",
    "                f\"Best: {best_val_loss:.6f}\"\n",
    "            )\n",
    "\n",
    "    # Load best model\n",
    "    checkpoint = torch.load(save_path, weights_only=True)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    return model\n",
    "\n",
    "print(\"[INFO] Exercise 12: train_model defined\")\n",
    "print(\"       (Requires DataLoaders to run — review the pattern)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13: Model Definition with Flexible Architecture\n",
    "\n",
    "**Prompt:** \"Write a simple but flexible MLP that could serve as a surrogate model.\"\n",
    "\n",
    "**Key `nn.Module` patterns tested:**\n",
    "- **`__init__`** — define layers (they get registered for `.parameters()`, `.to(device)`, `.state_dict()`)\n",
    "- **`forward`** — define computation graph (called via `model(x)`, NOT `model.forward(x)`)\n",
    "- **`nn.Sequential`** — chain layers into a single callable module\n",
    "- **Weight initialization** — Kaiming for ReLU/GELU, Xavier for sigmoid/tanh\n",
    "\n",
    "**Why `nn.Module` and not just functions?**\n",
    "```python\n",
    "# nn.Module gives you for FREE:\n",
    "model.parameters()        # All learnable params (for optimizer)\n",
    "model.to(\"cuda\")          # Move all params to GPU\n",
    "model.state_dict()        # Serializable dict of params\n",
    "model.train() / .eval()   # Toggle dropout/batchnorm\n",
    "model.children()          # Iterate sub-modules\n",
    "print(model)              # Human-readable architecture summary\n",
    "```\n",
    "\n",
    "**Dynamic layer construction pattern (this exercise):**\n",
    "```python\n",
    "layers = []\n",
    "in_dim = input_dim\n",
    "for h_dim in hidden_dims:        # e.g., [256, 256, 256]\n",
    "    layers.extend([\n",
    "        nn.Linear(in_dim, h_dim),\n",
    "        nn.LayerNorm(h_dim),     # Normalization\n",
    "        nn.GELU(),               # Activation\n",
    "        nn.Dropout(0.1),         # Regularization\n",
    "    ])\n",
    "    in_dim = h_dim               # Output of this layer → input of next\n",
    "\n",
    "self.backbone = nn.Sequential(*layers)  # Unpack list into Sequential\n",
    "self.head = nn.Linear(in_dim, output_dim)\n",
    "```\n",
    "\n",
    "**Weight initialization — why it matters:**\n",
    "```python\n",
    "# Default PyTorch init (Kaiming uniform) is usually fine\n",
    "# But explicit init shows you understand the theory:\n",
    "\n",
    "for m in self.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # Kaiming: designed for ReLU-family activations\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "        # Zero bias is standard\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "# Other options:\n",
    "# nn.init.xavier_normal_  → for sigmoid/tanh\n",
    "# nn.init.orthogonal_     → for RNNs\n",
    "# nn.init.constant_       → for specific values\n",
    "```\n",
    "\n",
    "**Activation function choices:**\n",
    "| Function | Formula | Use case |\n",
    "|----------|---------|----------|\n",
    "| ReLU | `max(0, x)` | Default, fast, can \"die\" (output always 0) |\n",
    "| GELU | `x · Φ(x)` | Transformers, smooth, no dead neurons |\n",
    "| SiLU/Swish | `x · σ(x)` | Modern CNNs, smooth |\n",
    "| Tanh | `(eˣ-e⁻ˣ)/(eˣ+e⁻ˣ)` | Output in [-1,1], can saturate |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Flexible MLP for surrogate modeling: params -> field values.\n",
    "\n",
    "    Demonstrates:\n",
    "    - Dynamic layer construction from config\n",
    "    - Multiple normalization options\n",
    "    - Proper weight initialization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        hidden_dims: List[int] = [256, 256, 256],\n",
    "        activation: str = \"gelu\",\n",
    "        norm: str = \"layer\",\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        act_fn = {\"relu\": nn.ReLU, \"gelu\": nn.GELU, \"silu\": nn.SiLU}[activation]\n",
    "        norm_fn = {\n",
    "            \"layer\": nn.LayerNorm,\n",
    "            \"batch\": nn.BatchNorm1d,\n",
    "            \"none\": lambda d: nn.Identity(),\n",
    "        }[norm]\n",
    "\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(in_dim, h_dim),\n",
    "                norm_fn(h_dim),\n",
    "                act_fn(),\n",
    "                nn.Dropout(dropout),\n",
    "            ])\n",
    "            in_dim = h_dim\n",
    "\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        self.head = nn.Linear(in_dim, output_dim)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"x: (batch, input_dim) -> (batch, output_dim)\"\"\"\n",
    "        return self.head(self.backbone(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 13\n",
    "model = SurrogateMLP(input_dim=10, output_dim=5, hidden_dims=[64, 64])\n",
    "x = torch.randn(4, 10)\n",
    "y = model(x)\n",
    "\n",
    "assert y.shape == (4, 5)\n",
    "y.sum().backward()\n",
    "\n",
    "# Count parameters\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "mb = total * 4 / (1024 ** 2)\n",
    "\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Parameters: {total:,} total, {trainable:,} trainable ({mb:.2f} MB)\")\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "print(\"[PASS] Exercise 13: SurrogateMLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14: Parameter Counting Utility\n",
    "\n",
    "**Prompt:** \"Write a function to count total and trainable parameters in a model.\"\n",
    "\n",
    "**Why this matters:**\n",
    "- **Paper reporting** — \"Our model has 1.2M parameters\" is standard in every ML paper\n",
    "- **Memory estimation** — `params × 4 bytes (float32) = model size in memory` (×2 for gradients during training)\n",
    "- **Architecture comparison** — helps decide between model variants\n",
    "- **Deployment constraints** — Synopsys may have memory/latency budgets for surrogate models\n",
    "\n",
    "**The one-liner you must memorize:**\n",
    "```python\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Memory estimation:\n",
    "# Training: params × 4 (weights) + params × 4 (gradients) + optimizer states\n",
    "# Inference: params × 4 (weights only) or params × 2 (float16)\n",
    "```\n",
    "\n",
    "**Frozen vs trainable parameters:**\n",
    "```python\n",
    "# Freeze a layer (transfer learning, fine-tuning):\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Now only model.head is trainable\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# This counts only head parameters\n",
    "```\n",
    "\n",
    "**Useful for comparing architectures:**\n",
    "```\n",
    "Hidden [64, 64]:         4,869 params (0.02 MB)  — too small?\n",
    "Hidden [256, 256, 256]: 133,893 params (0.51 MB)  — sweet spot\n",
    "Hidden [512, 512, 512]: 533,509 params (2.04 MB)  — maybe overkill\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def count_parameters(model: nn.Module) -> Dict[str, int]:\n",
    "    \"\"\"Count total and trainable parameters in a model.\"\"\"\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"trainable\": trainable,\n",
    "        \"frozen\": total - trainable,\n",
    "        \"total_MB\": total * 4 / (1024 ** 2),  # Assuming float32\n",
    "    }\n",
    "\n",
    "\n",
    "# Test with different model configs\n",
    "for hidden in [[64, 64], [256, 256, 256], [512, 512, 512, 512]]:\n",
    "    m = SurrogateMLP(input_dim=10, output_dim=5, hidden_dims=hidden)\n",
    "    p = count_parameters(m)\n",
    "    print(f\"Hidden {hidden}: {p['total']:>8,} params ({p['total_MB']:.2f} MB)\")\n",
    "\n",
    "print(\"[PASS] Exercise 14: count_parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15: MC-Dropout for Prediction Uncertainty\n",
    "\n",
    "**Prompt:** \"Add prediction uncertainty using MC-Dropout. This is critical for simulation surrogates — we need to know WHEN the model is uncertain.\"\n",
    "\n",
    "**Why uncertainty matters for Synopsys:**\n",
    "- A surrogate model that says \"I don't know\" is safer than one that silently gives wrong answers\n",
    "- High uncertainty → fall back to full HFSS simulation (expensive but accurate)\n",
    "- This is the same idea as your JESTIE paper's design-space coverage metric\n",
    "\n",
    "**Types of uncertainty:**\n",
    "\n",
    "| Type | Source | Can reduce with more data? | Method |\n",
    "|------|--------|---------------------------|--------|\n",
    "| **Aleatoric** | Noisy data, inherent randomness | No | Predict mean + variance |\n",
    "| **Epistemic** | Model doesn't know (insufficient data) | Yes | MC-Dropout, ensembles |\n",
    "\n",
    "**MC-Dropout — the simplest uncertainty method:**\n",
    "```python\n",
    "# Normal inference: dropout OFF → deterministic output\n",
    "model.eval()\n",
    "pred = model(x)  # Same input → same output every time\n",
    "\n",
    "# MC-Dropout: dropout ON at inference → stochastic output\n",
    "model.train()  # Keep dropout active! (the key trick)\n",
    "preds = []\n",
    "for _ in range(30):\n",
    "    with torch.no_grad():        # Still no gradients needed\n",
    "        preds.append(model(x))   # Each call drops different neurons\n",
    "\n",
    "preds = torch.stack(preds)       # (30, batch, output_dim)\n",
    "mean = preds.mean(dim=0)         # Best prediction\n",
    "std = preds.std(dim=0)           # Uncertainty estimate\n",
    "```\n",
    "\n",
    "**Interpreting the results:**\n",
    "```python\n",
    "# Low std  → model is confident → trust the prediction\n",
    "# High std → model is uncertain → run full simulation\n",
    "\n",
    "# Decision rule:\n",
    "threshold = 0.05  # Application-dependent\n",
    "uncertain_mask = std.mean(dim=-1) > threshold\n",
    "n_uncertain = uncertain_mask.sum()\n",
    "print(f\"{n_uncertain} samples need full HFSS simulation\")\n",
    "```\n",
    "\n",
    "**Alternatives to MC-Dropout:**\n",
    "| Method | Pros | Cons |\n",
    "|--------|------|------|\n",
    "| **MC-Dropout** | Simple, no extra training | Requires dropout layers, approximate |\n",
    "| **Deep Ensembles** | Best quality uncertainty | N× training cost, N× memory |\n",
    "| **Heteroscedastic** | Predicts per-point aleatoric | Doesn't capture epistemic |\n",
    "| **Bayesian NN** | Principled, full posterior | Slow, hard to scale |\n",
    "\n",
    "**For the interview:** MC-Dropout is the go-to answer because it's simple, effective, and requires zero changes to training — just keep `model.train()` at inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_uncertainty(\n",
    "    model: nn.Module,\n",
    "    x: torch.Tensor,\n",
    "    n_samples: int = 30,\n",
    "    device: str = \"cpu\",\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Monte Carlo Dropout for uncertainty estimation.\n",
    "\n",
    "    Runs N forward passes with dropout ENABLED at inference time.\n",
    "    The variance across predictions estimates epistemic uncertainty.\n",
    "\n",
    "    Args:\n",
    "        model: Model with Dropout layers (must have dropout > 0)\n",
    "        x: Input tensor, shape (batch, ...)\n",
    "        n_samples: Number of MC samples (30 is usually sufficient)\n",
    "\n",
    "    Returns:\n",
    "        mean: Mean prediction, shape same as model output\n",
    "        std:  Standard deviation (uncertainty), same shape\n",
    "    \"\"\"\n",
    "    model.train()  # Keep dropout ON (this is the key trick!)\n",
    "    x = x.to(device)\n",
    "\n",
    "    predictions = []\n",
    "    for _ in range(n_samples):\n",
    "        with torch.no_grad():  # Still no gradients needed\n",
    "            pred = model(x)\n",
    "        predictions.append(pred)\n",
    "\n",
    "    predictions = torch.stack(predictions)  # (n_samples, batch, ...)\n",
    "    mean = predictions.mean(dim=0)\n",
    "    std = predictions.std(dim=0)\n",
    "\n",
    "    model.eval()  # Restore to eval mode\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Exercise 15\n",
    "model_with_dropout = SurrogateMLP(\n",
    "    input_dim=10, output_dim=5, hidden_dims=[64, 64], dropout=0.1\n",
    ")\n",
    "x = torch.randn(4, 10)\n",
    "\n",
    "mean, std = predict_with_uncertainty(model_with_dropout, x, n_samples=50)\n",
    "\n",
    "assert mean.shape == (4, 5)\n",
    "assert std.shape == (4, 5)\n",
    "assert (std >= 0).all()\n",
    "\n",
    "print(f\"Mean prediction shape: {mean.shape}\")\n",
    "print(f\"Uncertainty (std) shape: {std.shape}\")\n",
    "print(f\"Mean uncertainty per output: {std.mean(dim=0)}\")\n",
    "print(f\"Max uncertainty: {std.max():.4f}\")\n",
    "print(\"[PASS] Exercise 15: MC-Dropout uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: PyTorch Gotchas — \"Spot the Bug\"\n",
    "\n",
    "Quick-fire questions an interviewer might ask. For each one: what's wrong and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 1: `model.eval()` does NOT disable gradients\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "model.eval()\n",
    "output = model(x)  # Still tracking gradients! Wastes memory.\n",
    "\n",
    "# FIX:\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "```\n",
    "\n",
    "**WHY:** `model.eval()` only changes Dropout and BatchNorm behavior. `torch.no_grad()` disables autograd for memory/speed savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 2: In-place operations break autograd\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "x += 1            # In-place! Destroys grad graph.\n",
    "loss = x.sum()\n",
    "loss.backward()   # RuntimeError\n",
    "\n",
    "# FIX:\n",
    "y = x + 1         # New tensor — graph intact.\n",
    "```\n",
    "\n",
    "**RULE:** Any operation ending in `_` (`add_`, `mul_`, `zero_`) is in-place. Never use on tensors that need gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 3: Device mismatch\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "model = model.cuda()\n",
    "x = torch.randn(4, 10)   # CPU!\n",
    "output = model(x)         # RuntimeError\n",
    "\n",
    "# FIX:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "x = x.to(device)\n",
    "```\n",
    "\n",
    "**TIP:** Inside a model, create new tensors on the same device as input: `mask = torch.ones(n, device=x.device)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 4: Forgetting `model.train()` after validation\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "model.eval()\n",
    "val_loss = validate(model)\n",
    "# ... continue training with Dropout disabled, BatchNorm frozen ...\n",
    "\n",
    "# FIX:\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss = validate(model)\n",
    "model.train()  # ALWAYS switch back!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 5: Gradient accumulation (forgetting `zero_grad`)\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "for batch in dataloader:\n",
    "    loss = model(batch).sum()\n",
    "    loss.backward()       # Gradients ACCUMULATE from prior steps!\n",
    "    optimizer.step()\n",
    "\n",
    "# FIX:\n",
    "for batch in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(batch).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "**NOTE:** Accumulation is actually *useful* for simulating larger batch sizes:\n",
    "```python\n",
    "for i, batch in enumerate(dataloader):\n",
    "    loss = model(batch).sum() / accumulation_steps\n",
    "    loss.backward()\n",
    "    if (i + 1) % accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 6: Silent broadcasting bugs\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "pred = model(x)       # (batch, 10)\n",
    "target = get_target() # (batch,)\n",
    "loss = (pred - target) ** 2  # Broadcasts to (batch, 10) — WRONG!\n",
    "\n",
    "# FIX:\n",
    "target = target.unsqueeze(-1)  # (batch, 1) — explicit shape\n",
    "loss = (pred - target) ** 2\n",
    "```\n",
    "\n",
    "**DEFENSE:** Always `assert pred.shape == target.shape`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 7: Memory leak from storing loss tensors\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "losses = []\n",
    "for batch in dataloader:\n",
    "    loss = model(batch).sum()\n",
    "    losses.append(loss)  # Entire computation graph stays in memory!\n",
    "\n",
    "# FIX:\n",
    "losses.append(loss.item())   # .item() -> Python float, graph freed\n",
    "# or\n",
    "losses.append(loss.detach()) # Tensor without grad history\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 8: BatchNorm with `batch_size=1`\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "model = nn.Sequential(nn.Linear(10, 10), nn.BatchNorm1d(10))\n",
    "x = torch.randn(1, 10)  # Single sample!\n",
    "model(x)                 # RuntimeError: variance is 0\n",
    "```\n",
    "\n",
    "**FIX:** Use `LayerNorm` (normalizes across features) or `InstanceNorm`. For simulation data with small batches, `LayerNorm` is usually better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 9: DDP `state_dict` key mismatch\n",
    "\n",
    "```python\n",
    "# BUG: Saved with DDP → keys = \"module.layer.weight\"\n",
    "#       Loaded without DDP → expects \"layer.weight\"\n",
    "\n",
    "# FIX (save correctly):\n",
    "torch.save(ddp_model.module.state_dict(), \"model.pt\")\n",
    "\n",
    "# FIX (load flexibly):\n",
    "state = torch.load(\"model.pt\")\n",
    "state = {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n",
    "model.load_state_dict(state)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 10: `torch.Tensor` vs `torch.tensor`\n",
    "\n",
    "```python\n",
    "# BUG:\n",
    "x = torch.Tensor(3)     # Allocates UNINITIALIZED tensor of size 3!\n",
    "y = torch.Tensor([1,2]) # Always float32, ignores input dtype\n",
    "\n",
    "# FIX:\n",
    "x = torch.tensor(3)     # Scalar tensor with value 3\n",
    "y = torch.tensor([1,2]) # Infers dtype (int64 here)\n",
    "```\n",
    "\n",
    "**RULE:** Always use lowercase `torch.tensor()` for creating from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Essential Patterns Quick Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Pattern 1: Proper training loop skeleton\n",
    "# =====================================================\n",
    "# model.train()\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = criterion(model(batch.to(device)), target.to(device))\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         optimizer.step()\n",
    "\n",
    "# =====================================================\n",
    "# Pattern 2: Proper evaluation\n",
    "# =====================================================\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for batch in val_loader:\n",
    "#         pred = model(batch.to(device))\n",
    "# model.train()  # Switch back!\n",
    "\n",
    "# =====================================================\n",
    "# Pattern 3: Proper checkpointing\n",
    "# =====================================================\n",
    "# torch.save({\n",
    "#     'epoch': epoch,\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'loss': best_loss,\n",
    "# }, 'checkpoint.pt')\n",
    "#\n",
    "# ckpt = torch.load('checkpoint.pt', weights_only=True)\n",
    "# model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "# =====================================================\n",
    "# Pattern 4: Mixed precision (AMP)\n",
    "# =====================================================\n",
    "# scaler = torch.amp.GradScaler(\"cuda\")\n",
    "# with torch.amp.autocast(\"cuda\"):\n",
    "#     loss = model(x)\n",
    "# scaler.scale(loss).backward()\n",
    "# scaler.step(optimizer)\n",
    "# scaler.update()\n",
    "\n",
    "# =====================================================\n",
    "# Pattern 5: Gradient accumulation\n",
    "# =====================================================\n",
    "# for i, batch in enumerate(loader):\n",
    "#     loss = model(batch) / accum_steps\n",
    "#     loss.backward()\n",
    "#     if (i + 1) % accum_steps == 0:\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "print(\"Review the 5 essential patterns above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Run All Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RUNNING ALL TESTS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Part 1: Python Fundamentals\n",
    "print(\"--- Part 1: Python Fundamentals ---\")\n",
    "\n",
    "# Ex 1\n",
    "results = [\n",
    "    {\"geometry\": \"dipole\", \"error\": 0.05},\n",
    "    {\"geometry\": \"patch\",  \"error\": 0.12},\n",
    "    {\"geometry\": \"dipole\", \"error\": 0.03},\n",
    "    {\"geometry\": \"patch\",  \"error\": 0.08},\n",
    "]\n",
    "avg = group_and_average(results)\n",
    "assert abs(avg[\"dipole\"] - 0.04) < 1e-10\n",
    "print(\"  [PASS] Exercise 1: group_and_average\")\n",
    "\n",
    "# Ex 3\n",
    "s_params = np.random.randn(10, 2, 2) + 1j * np.random.randn(10, 2, 2)\n",
    "freqs = np.linspace(1.0, 10.0, 10)\n",
    "result = SimulationResult(\"test_antenna\", s_params, freqs)\n",
    "assert result.n_ports == 2\n",
    "print(f\"  [PASS] Exercise 3: SimulationResult\")\n",
    "\n",
    "# Ex 5\n",
    "config = {\"model_type\": \"gnn\", \"learning_rate\": 1e-3, \"num_epochs\": 50}\n",
    "clean = validate_config(config)\n",
    "assert clean[\"batch_size\"] == 32\n",
    "print(\"  [PASS] Exercise 5: validate_config\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Part 2: Tensor Operations\n",
    "print(\"--- Part 2: Tensor Operations ---\")\n",
    "\n",
    "# Ex 6\n",
    "x = torch.randn(5, 3); y = torch.randn(7, 3)\n",
    "dist = pairwise_distances(x, y)\n",
    "assert torch.allclose(dist, torch.cdist(x, y), atol=1e-5)\n",
    "print(\"  [PASS] Exercise 6: pairwise_distances\")\n",
    "\n",
    "# Ex 7\n",
    "agg = gather_scatter_demo(torch.randn(4, 8), torch.tensor([[0,1,2,3],[1,2,3,0]]))\n",
    "assert agg.shape == (4, 8)\n",
    "print(\"  [PASS] Exercise 7: gather_scatter\")\n",
    "\n",
    "# Ex 8\n",
    "e, f, fd = filter_simulation_data(\n",
    "    torch.tensor([0.05, 0.15, 0.03, 0.20, 0.08]),\n",
    "    torch.tensor([2e9, 5e9, 3e9, 15e9, 8e9]),\n",
    "    torch.randn(5, 4, 4)\n",
    ")\n",
    "assert len(e) == 3\n",
    "print(\"  [PASS] Exercise 8: filter_simulation_data\")\n",
    "\n",
    "# Ex 9\n",
    "rel = per_sample_relative_l2(torch.randn(4,16,16), torch.randn(4,16,16)+5)\n",
    "assert rel.shape == (4,) and (rel >= 0).all()\n",
    "print(\"  [PASS] Exercise 9: per_sample_relative_l2\")\n",
    "\n",
    "# Ex 10\n",
    "normed = per_sample_normalize(torch.randn(2,3,8,8)*100+50)\n",
    "assert torch.allclose(normed.mean(dim=(-2,-1)), torch.zeros(2,3), atol=1e-5)\n",
    "print(\"  [PASS] Exercise 10: per_sample_normalize\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Part 3: PyTorch Patterns\n",
    "print(\"--- Part 3: PyTorch Patterns ---\")\n",
    "\n",
    "# Ex 13\n",
    "m = SurrogateMLP(10, 5, [64,64])\n",
    "y = m(torch.randn(4,10)); y.sum().backward()\n",
    "print(f\"  [PASS] Exercise 13: SurrogateMLP ({sum(p.numel() for p in m.parameters()):,} params)\")\n",
    "\n",
    "# Ex 15\n",
    "md = SurrogateMLP(10, 5, [64,64], dropout=0.1)\n",
    "mean, std = predict_with_uncertainty(md, torch.randn(4,10), n_samples=10)\n",
    "assert mean.shape == (4,5) and (std >= 0).all()\n",
    "print(\"  [PASS] Exercise 15: MC-Dropout uncertainty\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"ALL TESTS PASSED\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}